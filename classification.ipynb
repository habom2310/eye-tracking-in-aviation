{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygaze\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "import detectors\n",
    "import gazeplotter\n",
    "from collections import defaultdict\n",
    "# import local lib\n",
    "import eye_metrics_utils\n",
    "import data_utils\n",
    "import gaze_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings(action='once')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(df_data):\n",
    "    df_x = df_data.copy()\n",
    "    if (data_utils.check_percentage_null(df_x) < 0.5): # if missing value > 50%, remove\n",
    "        return None\n",
    "    \n",
    "    time = np.array(df_data['Start Time (secs)'].tolist())\n",
    "\n",
    "    Efix = eye_metrics_utils.detect_fixations(df_x)\n",
    "#     print(Efix)\n",
    "    X = np.array(Efix).T[3:].T\n",
    "    Hs, Ht = gaze_entropy.entropy(X)\n",
    "    total_time = time[-1] - time[0]\n",
    "    \n",
    "    return Efix, Hs, Ht, total_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"data/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_one = [v for v in csv_files if \"One Gaze-Vergence\" in v]\n",
    "csv_files_two = [v for v in csv_files if \"Two Gaze-Vergence\" in v]\n",
    "csv_files_three = [v for v in csv_files if \"Three Go-Around Gaze-Vergence\" in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['032', '027', '031', '028', '004', '008', '010', '029', '003', '007', '023'],\n",
       " ['021',\n",
       "  '006',\n",
       "  '019',\n",
       "  '022',\n",
       "  '015',\n",
       "  '016',\n",
       "  '014',\n",
       "  '005',\n",
       "  '025',\n",
       "  '002',\n",
       "  '001',\n",
       "  '020',\n",
       "  '011',\n",
       "  '017']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_par = pd.read_csv(\"participant.csv\")\n",
    "group = [df_par[df_par['Group'].str.contains(\"1\")]['ID'].tolist(), df_par[df_par['Group'].str.contains(\"2\")][\"ID\"].tolist()]\n",
    "group = [[i[-3:] for i in v] for v in group]\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\PISSS_ID_003_Approach One Gaze-Vergence.csv\n",
      "9122\n",
      "data\\PISSS_ID_004_Approach One Gaze-Vergence.csv\n",
      "9307\n",
      "data\\PISSS_ID_007_Approach One Gaze-Vergence.csv\n",
      "9492\n",
      "data\\PISSS_ID_008_Approach One Gaze-Vergence.csv\n",
      "9736\n",
      "data\\PISSS_ID_010_Approach One Gaze-Vergence.csv\n",
      "9554\n",
      "data\\PISSS_ID_023_Approach One Gaze-Vergence.csv\n",
      "9369\n",
      "data\\PISSS_ID_027_Approach One Gaze-Vergence.csv\n",
      "9060\n",
      "data\\PISSS_ID_028_Approach One Gaze-Vergence.csv\n",
      "8999\n",
      "data\\PISSS_ID_029_Approach One Gaze-Vergence.csv\n",
      "9862\n",
      "data\\PISSS_ID_031_Approach One Gaze-Vergence.csv\n",
      "9677\n",
      "data\\PISSS_ID_032_Approach One Gaze-Vergence.csv\n",
      "8629\n",
      "data\\PISSS_ID_003_Approach Two Gaze-Vergence.csv\n",
      "9368\n",
      "data\\PISSS_ID_004_Approach Two Gaze-Vergence.csv\n",
      "9862\n",
      "data\\PISSS_ID_007_Approach Two Gaze-Vergence.csv\n",
      "9677\n",
      "data\\PISSS_ID_008_Approach Two Gaze-Vergence.csv\n",
      "9923\n",
      "data\\PISSS_ID_010_Approach Two Gaze-Vergence.csv\n",
      "9923\n",
      "data\\PISSS_ID_023_Approach Two Gaze-Vergence.csv\n",
      "9677\n",
      "data\\PISSS_ID_027_Approach Two Gaze-Vergence.csv\n",
      "8568\n",
      "data\\PISSS_ID_028_Approach Two Gaze-Vergence.csv\n",
      "9554\n",
      "data\\PISSS_ID_029_Approach Two Gaze-Vergence.csv\n",
      "10232\n",
      "data\\PISSS_ID_031_Approach Two Gaze-Vergence.csv\n",
      "9923\n",
      "data\\PISSS_ID_032_Approach Two Gaze-Vergence.csv\n",
      "8011\n",
      "data\\PISSS_ID_003_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2157\n",
      "data\\PISSS_ID_004_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1849\n",
      "data\\PISSS_ID_007_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2096\n",
      "data\\PISSS_ID_010_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2589\n",
      "data\\PISSS_ID_023_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1849\n",
      "data\\PISSS_ID_027_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2280\n",
      "data\\PISSS_ID_028_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2157\n",
      "data\\PISSS_ID_029_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1725\n",
      "data\\PISSS_ID_031_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1849\n",
      "data\\PISSS_ID_032_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1911\n",
      "data\\PISSS_ID_001_Approach One Gaze-Vergence.csv\n",
      "9307\n",
      "data\\PISSS_ID_002_Approach One Gaze-Vergence.csv\n",
      "9184\n",
      "data\\PISSS_ID_005_Approach One Gaze-Vergence.csv\n",
      "8567\n",
      "data\\PISSS_ID_006_Approach One Gaze-Vergence.csv\n",
      "9985\n",
      "data\\PISSS_ID_011_Approach One Gaze-Vergence.csv\n",
      "9492\n",
      "data\\PISSS_ID_014_Approach One Gaze-Vergence.csv\n",
      "9369\n",
      "data\\PISSS_ID_015_Approach One Gaze-Vergence.csv\n",
      "27978\n",
      "data\\PISSS_ID_016_Approach One Gaze-Vergence.csv\n",
      "8259\n",
      "data\\PISSS_ID_017_Approach One Gaze-Vergence.csv\n",
      "10046\n",
      "data\\PISSS_ID_019_Approach One Gaze-Vergence.csv\n",
      "9615\n",
      "data\\PISSS_ID_020_Approach One Gaze-Vergence.csv\n",
      "9800\n",
      "data\\PISSS_ID_021_Approach One Gaze-Vergence.csv\n",
      "9492\n",
      "data\\PISSS_ID_022_Approach One Gaze-Vergence.csv\n",
      "9615\n",
      "data\\PISSS_ID_025_Approach One Gaze-Vergence.csv\n",
      "8382\n",
      "data\\PISSS_ID_001_Approach Two Gaze-Vergence.csv\n",
      "9554\n",
      "data\\PISSS_ID_002_Approach Two Gaze-Vergence.csv\n",
      "9430\n",
      "data\\PISSS_ID_005_Approach Two Gaze-Vergence.csv\n",
      "9245\n",
      "data\\PISSS_ID_006_Approach Two Gaze-Vergence.csv\n",
      "9739\n",
      "data\\PISSS_ID_011_Approach Two Gaze-Vergence.csv\n",
      "9492\n",
      "data\\PISSS_ID_014_Approach Two Gaze-Vergence.csv\n",
      "9307\n",
      "data\\PISSS_ID_015_Approach Two Gaze-Vergence.csv\n",
      "8812\n",
      "data\\PISSS_ID_016_Approach Two Gaze-Vergence.csv\n",
      "8259\n",
      "data\\PISSS_ID_017_Approach Two Gaze-Vergence.csv\n",
      "9184\n",
      "data\\PISSS_ID_019_Approach Two Gaze-Vergence.csv\n",
      "9615\n",
      "data\\PISSS_ID_020_Approach Two Gaze-Vergence.csv\n",
      "9923\n",
      "data\\PISSS_ID_021_Approach Two Gaze-Vergence.csv\n",
      "9369\n",
      "data\\PISSS_ID_022_Approach Two Gaze-Vergence.csv\n",
      "9307\n",
      "data\\PISSS_ID_025_Approach Two Gaze-Vergence.csv\n",
      "8937\n",
      "data\\PISSS_ID_001_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2465\n",
      "data\\PISSS_ID_002_Approach Three Go-Around Gaze-Vergence.csv\n",
      "616\n",
      "data\\PISSS_ID_005_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2230\n",
      "data\\PISSS_ID_006_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2033\n",
      "data\\PISSS_ID_011_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2157\n",
      "data\\PISSS_ID_014_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2096\n",
      "data\\PISSS_ID_015_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2033\n",
      "data\\PISSS_ID_016_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2219\n",
      "data\\PISSS_ID_017_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2650\n",
      "data\\PISSS_ID_019_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1541\n",
      "data\\PISSS_ID_020_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1665\n",
      "data\\PISSS_ID_021_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1726\n",
      "data\\PISSS_ID_022_Approach Three Go-Around Gaze-Vergence.csv\n",
      "1972\n",
      "data\\PISSS_ID_025_Approach Three Go-Around Gaze-Vergence.csv\n",
      "2342\n"
     ]
    }
   ],
   "source": [
    "feature_groups = []\n",
    "for g in group:\n",
    "    trials = []\n",
    "    for csv_files in [csv_files_one, csv_files_two, csv_files_three]:\n",
    "        ret = defaultdict(list)\n",
    "        for csv in csv_files:\n",
    "            par_id = csv[14:17]\n",
    "            if par_id not in g:\n",
    "                continue\n",
    "                \n",
    "            print(csv)\n",
    "            df_data = pd.read_csv(csv)\n",
    "            print(len(df_data))\n",
    "            for v in data_utils.data_slicing(df_data):\n",
    "                r = run_all(v)\n",
    "                if r != None:\n",
    "                    Efix, Hs, Ht, total_time = r\n",
    "#                     ret[\"Eblk\"].append(Eblk)\n",
    "                    ret[\"Efix\"].append(Efix)\n",
    "#                     ret[\"Esac\"].append(Esac)\n",
    "#                     ret[\"trans_matrix\"].append(trans_matrix)\n",
    "                    ret[\"Hs\"].append(Hs)\n",
    "                    ret[\"Ht\"].append(Ht)\n",
    "                    ret[\"total_time\"].append(total_time)\n",
    "        trials.append(ret)\n",
    "    feature_groups.append(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix_dur</th>\n",
       "      <th>Hs</th>\n",
       "      <th>Ht</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.487013</td>\n",
       "      <td>1.890805</td>\n",
       "      <td>1.541628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185009</td>\n",
       "      <td>1.515655</td>\n",
       "      <td>1.316056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163963</td>\n",
       "      <td>0.954434</td>\n",
       "      <td>0.911104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518010</td>\n",
       "      <td>0.995727</td>\n",
       "      <td>0.942766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116004</td>\n",
       "      <td>0.949452</td>\n",
       "      <td>0.896885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.372018</td>\n",
       "      <td>0.899744</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.324005</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>0.956601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.080001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.226009</td>\n",
       "      <td>1.571542</td>\n",
       "      <td>1.022576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.132028</td>\n",
       "      <td>0.881291</td>\n",
       "      <td>0.697009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fix_dur        Hs        Ht  group\n",
       "0  0.487013  1.890805  1.541628      0\n",
       "1  0.185009  1.515655  1.316056      0\n",
       "2  0.163963  0.954434  0.911104      0\n",
       "3  0.518010  0.995727  0.942766      0\n",
       "4  0.116004  0.949452  0.896885      0\n",
       "5  0.372018  0.899744  0.870875      0\n",
       "6  0.324005  0.998001  0.956601      0\n",
       "7  0.080001  0.000000  0.000000      0\n",
       "8  0.226009  1.571542  1.022576      0\n",
       "9  0.132028  0.881291  0.697009      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = pd.DataFrame()\n",
    "for j, g in enumerate(feature_groups):\n",
    "    fix_dur = []\n",
    "    for i, p in enumerate(g[1]['Efix']):\n",
    "        fix_dur = np.append(fix_dur,np.array(p).T[2])\n",
    "    Hs = g[1]['Hs']\n",
    "    Ht = g[1]['Ht']\n",
    "    group = j*np.ones_like(Hs)\n",
    "    df = pd.DataFrame(zip(fix_dur, Hs, Ht, group), columns=[\"fix_dur\", \"Hs\", \"Ht\", \"group\"]).astype({\"group\":\"int\"})\n",
    "    df_x = pd.concat([df_x, df])\n",
    "    \n",
    "df_x.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fix_dur    float64\n",
       "Hs         float64\n",
       "Ht         float64\n",
       "group        int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396396396396397"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_x[['fix_dur', 'Hs', 'Ht']].values\n",
    "y = df_x[['group']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "# clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[[-1.03691331 -0.10537734  0.38811859]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.classes_)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     group 1       0.76      0.31      0.44       102\n",
      "     group 2       0.61      0.92      0.73       120\n",
      "\n",
      "    accuracy                           0.64       222\n",
      "   macro avg       0.69      0.62      0.59       222\n",
      "weighted avg       0.68      0.64      0.60       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "target_names = ['group 1', 'group 2']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
